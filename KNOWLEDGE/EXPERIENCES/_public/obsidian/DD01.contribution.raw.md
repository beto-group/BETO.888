










```
1. To start this channel off with a brief snapshot of the world on Datacore:
    
    - There is essentially a fully featured document query engine and language, plus caching, sitting around. It can do block, section, and page level queries over metadata and stores a fairly substantial amount of document information right now.
    - I am currently focusing on making the **DatacoreJS** functionality work at a very high level - the beta version of the plugin is going to be power user oriented and will expose JS apis for making very high powered views.
    - JSX and TypeScript are also already supported via (`datacorets` and `datacorejsx` and `datacoretsx`) - using the `sucrase` transpiler. Neat!
    - There are tons of bits and bobs that I would like to implement but haven't got around to.
    
    ![ðŸ’ª](https://discord.com/assets/f325a6b9cd5db99d48cd.svg)
    
    4
    
    ![](https://discord.com/assets/3a959ff5232e38b81569.svg)
    
    ![](https://discord.com/assets/e88d836986235fb50ed5.svg)
    
    ![](https://discord.com/assets/27311c5caafe667efb19.svg)
    
2. _[_10:22 PM_]_
    
    In terms of things to implement in the immediate horizon that may tickle someone's interest:
    
    - Editable components. The indices contain the metadata required to edit things (via the `Field` abstraction), but I haven't written the actual function that takes a field and updates it's value to a new value. I also have not implemented any react components which then use this API to show a pretty edit box. There is some nuance to this with refreshing - any implementation here needs to make sure that user edits don't get wiped out by a concurrent update to the view.
    - Fast embedding of blocks, sections, etc. There is logic which supports native Obsidian embedding but this only works for sections and tagged blocks. We have logic for embedding using line numbers, but need to expose it on the API, potentially in some fancy way by adding an abstraction or something.
    - Lots of visual components. I'd like to have a few "universal" components like buttons, button groups, textboxes, maybe dropdowns/selectors, which scripts can use to make interactive views.
    - Performance. Datacore performance is fine but initial indexing is notably slower than Dataview - I'm not really sure why since the performance graphs mostly show lots of idle time.
    - Some "Batteries Included" Views: A simple table view, an image gallery view, a card view, and a list view as the fundamental set. There is also the potential for a few charts views - though be careful here with including enormous dependencies like d3.
    - Query Language Improvements: The query language is essentially the same as Dataview's which has a few warts I want to fix. Specifically, I'd like to implement infix functions (where `a.contains(b)` is implicitly parsed as `contains(a, b)` for you) and the `in` operator (which just does what the Python operator does).
```



```

```




ENIGMAS


PROBLEM 

Yes, I saw that - batching in groups of 8-16 would be a huge speedup.
1. Maybe even more.
2. The runtime currently is putting pauses in between every single import annoyingly.



ANSWER


1. though if you can use WASM and shared memory via shared array buffer, you can communicate between workers quite easily, but not with the main thread, as you are not allowed to wait on the main thread

lock free and without the wasm atomic await instructions


1. so with some sort of spin lock, but that sucks as well


1. i guess you need some channel (main -> worker) that is lock and await free and then for (worker -> main) you would need to do some sort if poll interval with a timeout maybe?




----

CONSIDERATION


I'll look at it a bit later this afternoon, but off the top of my head there are two things to be careful about:
- It's possible for `dc.require()` to be called recursively by subscripts themselves, and for these subscripts to all `dc.require()` the same sub-sub-script. It's also possible for scripts to try to load each other in a cycle. The way to "fix" this is to have dc.require() return a Javascript Proxy object and have a cache of currently loading/successfully loaded scripts.
- Datacore has a "persistent render" model, where the script is only executed once and then React is used to handle changes to file metadata. Dataview would just rerun the entire script every time. As a result,  we want the datacore script to rerun itself if any of the script files it depends on change (since they are kind of hard to live reload).


if i bring back the `ScriptCache` added in [this commit](https://github.com/blacksmithgu/datacore/commit/866b5be02b0eeea3537739c4f2416da50121c193), should i store the cache for loaded script info in `DataStore` or just `ScriptCache`?


The caching only needs to be done per view, so probably inside `DatacoreLocalApi` is fine.

You can also do in `DatacoreJSRenderer` maybe.

But the API is probably easiest.


is the `LOADING_SENTINEL` symbol necessary?


It's how that code was tracking which scripts are in the middle of being loaded.


This happens when you `require` a script that then `requires` something else - the middle script will be "loading" until the other script has loaded.


  
What's the syntax that it accepts, and what is the file type that it accepts? Does the file have to be in the root folder?

	I added an example in `docs/javascript.md`




----

## PROBLEM

I've been looking at import performance and it appears that the biggest issue right now is `IndexedDb` (which I use for caching file metadata) is taking 2-3 seconds to actually load metadata for some documents. Not really sure what's going on there and why it's so much slower than Dataview, which also uses IndexedDb...


I'd expect latency of ~1ms/document at most...



----

QUESTION

re: editing in table views - if i were to implement this, should i create a function that "smartly" detects *what* the user is trying to edit, and updates the appropriate field/item is accordingly?


ANSWER

The simplest approach is going to be writing components that allow a single specified field to be updated. There is a `Field` abstraction already which contains the metadata about the type and origin of the field which can be used here. The usage would be something like

```
const EDITABLE_COLUMN = { 
  id: "example-editable",
  value: page => page.value("rating"),
  render: (rating, page) => <dc.EditableSlider field={page.field("rating")} ... />
};
```

In other words, just hook up the existing editable stuff and create components that support editing.

Forcing the user to specify how the field should be edited avoids the really ugly/jank stuff of "how do you handle nulls?" or "what if this field is a number on one page but a string on another?".

We can expand the functionality later to something better / more automatic but this should be a very solid start.


Having a textbox/textarea editor for text, a specialized one for numeric inputs, a date picker (maybe the obsidian default one?), the existing sliders/rating one are all good starting things.



LOl changes mind like mindset

Looks interesting. What does the actual underlying data look like here? Is this rendering a tree of data essentially?


ANSWER

the underlying data is recursively grouped tasks. here's the function i wrote to handle this:

```js
const groupFn = x => {
        let variable = x.$elements || [];
            return {
                key: x.key || x,
                rows: variable.map(groupFn)
            }
    }
```


i made a branch that adds a `displayAsRow` boolean property to `GroupingConfig`, that dictates whether the group will be rendered as a header or a regular table row




Where the key is used to render the column?'


in `VanillaRowGroup`, i also made it so that it renders out a regular table row or a table group header depending on the `displayAsRow` prop

something like

groupingConfig?.displayAsRow ? (
                    <TableRow
                        open={open}
                        openChanged={setOpen}
                        row={element.key as T}
                        columns={columns}
                        level={level}
                        hasChildren={element.rows.length > 0}
                    />
                ) : (
                    <TableGroupHeader
                        level={level}
                        value={element}
                        width={columns.length}
                        config={groupingConfig}
                        open={open}
                        openChanged={setOpen}
                    />
                )}


updated `TableRow` looks like

```
export function TableRow<T>({
    level,
    row,
    columns,
    openChanged,
    open,
    hasChildren = false,
}: {
    level: number;
    row: T;
    columns: VanillaColumn<T>[];
    openChanged: (b: boolean) => void;
    open: boolean;
    hasChildren?: boolean;
}) {
    return (
        <tr className="datacore-table-row" data-level={level}>
            <td style={level ? `padding-left: ${level * 25}px;` : undefined}>
                {hasChildren ? <TableCollapser open={open} openChanged={openChanged} /> : null}
            </td>
            {columns.map((col) => (
                <TableRowCell row={row} column={col} level={level} />
            ))}
        </tr>
    );
}



`data-level` is just there for debugging purposes


QUESTION

Does `open` / `setOpen` work here?

This seems fine as an approach; I'd have to mess with it to see what it looks like in practice, esp for deep nesting where I have no idea what lots of left padding will do to the table layout.

ANSWER

yep! it controls the collapsing and expanding





This will likely need to be adjusted a bit - React will not save this open state across pages, so if I go forward a page and then back all of the state will be lost. As a result, it probably needs to be tracked at the top level of the view somehow, but that means each row needs an ID of some sort so you can identify each one.

There are actually other benefits to trying to identify rows by some unique ID but I have to figure out what ID to use. The easiest is just to use the index of each row in the input data, but that changes whenever you sort the data or get new results from the index; the 'best' would be to use the `$id` property of each row, though this only works if you are using indexable types and breaks if you have multiple rows with the same `$id`. A bit annoying.

 good news: i implemented editing in the VanillaTable 
bad news: i can't test right now because i think i borked my eyes from too much screen time ðŸ˜…


the text column looks like this:


{
    id: "texto",
    title: "text",
    value: x => x.$cleanText,
    editable: true,
    onUpdate: (v, x) => dc.setTaskText(v, x),
editor: (v, o, d) => <dc.TextEditor dispatch={d} text={v} inline={false}/>,
     render: (v, o) => <dc.Markdown content={v} inline/>
}

should i begin work on canvas indexing? also what happened to indexing pdfs?
i noticed a few commits back that pdf support was removed


You can look at canvas' if you'd like.
The PDF indexing broke in a few ways for reasons I wasn't able to debug in time for a release, so I disabled it for now.


----

PROBLEM

You can look at canvas' if you'd like.

The PDF indexing broke in a few ways for reasons I wasn't able to debug in time for a release, so I disabled it for now.


QUESTION BACK

when you say it broke, what exactly do you mean?



The canvas indexing PR has merged.

Two things I remember:
- The web worker was pulling the pdfjs dist directly from a CDN and was breaking when I was offline - we should avoid doing this and either (1) use the pdf.js that comes with obsidian or (2) bundle it ourselves.
- I can't remember the precise error I was getting but every PDF file was failing to parse via pdfjs and silently failing.


would you be okay with the final main.js size if we bundled it ourselves? ðŸ¥²


also option 1 is simply impossible because global variables declared in the main thread aren't available in workers (for some ungodly reason)
believe me i've tried


One kind of hacky option is to handle pdfs on the main thread but I'm not sure if it would affect perf heavily.

i know pdfjs internally uses a worker of its own to process pdfs


so the processing happens outside of the main thread

Yes, that might be fine.


update: despite the size of the pdfjs npm package, the production bundle is only 3mb

only with source maps etc is it closer to the size shown above

man, pdfs don't really have much useful metadata do they? ðŸ¥´


Yeah it is a pretty heavy price to pay to index them just to get like... the number of pages

You could honestly probably write some shit pdf parsing code that got the number of pages in 1/1000th of the size requirement



----

hey I noted the repo didn't have any CI/CD setup at present. Happy to accept MRs to add some in? Formatting linting checking etc.

Yup, would appreciate CI!



----

Hi  . Is there a chance you could share the entire code for this example?


---

i'll let you be the judge of that ðŸ™ˆ



----

PROBLEM

also apologies for the inline fields not displaying in the source unless i put my cursor over them. obsidian doesn't seem to want to render multiple inline fields if they don't have at least 2 spaces between them...

you need a , inbetween
it is a markdown thing

the problem is that  [ ][ ] links exist in markdown


---

they seem to be called reference style links



For performance, the editing should scale fine regardless of vault size.

The main 'slow' part of datacore is the initial indexing - it will probably be somewhat memory hungry if you have large (10,000+ note) vaults.

how do you feel about moving away from indexeddb for datacore? we could use sqlite -- it works on both mobile (left) and desktop

code can be found here https://git.tablet.sh/tablet/obsidian-sqlite-opfs

---


how do you feel about moving away from indexeddb for datacore? we could use sqlite -- it works on both mobile (left) and desktop

code can be found here https://git.tablet.sh/tablet/obsidian-sqlite-opfs


What benefit would we get from WASM-d sqlite?

1. I'm not very picky about what we use for the persistence layer but want to make sure we're moving towards something better./
i'll take some benchmarks to see which is faster -- indexeddb or OPFS-backed sqlite


first image: indexeddb vs sqlite's plain OPFS vfs
second image: indexeddb vs sqlite's `SyncAccessHandle` OPFS vfs


sqlite is very fast in most code bases but I am guessing the WASM overhead really kills performance.

namely firefox and its derivatives

chromium, and by extension electron, uses leveldb


i opened another PR to add view pages!

https://github.com/blacksmithgu/datacore/pull/62